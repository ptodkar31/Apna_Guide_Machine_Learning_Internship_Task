{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e02de152",
   "metadata": {},
   "source": [
    "# Disaster or Not?\n",
    "\n",
    "Twitter has emerged as a vital platform for communication during emergencies. The widespread use of smartphones allows individuals to report emergencies as they happen in real time. Consequently, an increasing number of organizations, including disaster relief agencies and news outlets, are showing interest in systematically tracking Twitter.\n",
    "However, determining whether someone's posts genuinely indicate a disaster can often be challenging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69bae564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>place</th>\n",
       "      <th>tweet</th>\n",
       "      <th>disaster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword place                                              tweet  \\\n",
       "0         1     NaN   NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1         4     NaN   NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2         5     NaN   NaN  All residents asked to 'shelter in place' are ...   \n",
       "3         6     NaN   NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4         7     NaN   NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "...     ...     ...   ...                                                ...   \n",
       "7608  10869     NaN   NaN  Two giant cranes holding a bridge collapse int...   \n",
       "7609  10870     NaN   NaN  @aria_ahrary @TheTawniest The out of control w...   \n",
       "7610  10871     NaN   NaN  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...   \n",
       "7611  10872     NaN   NaN  Police investigating after an e-bike collided ...   \n",
       "7612  10873     NaN   NaN  The Latest: More Homes Razed by Northern Calif...   \n",
       "\n",
       "      disaster  \n",
       "0            1  \n",
       "1            1  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  \n",
       "...        ...  \n",
       "7608         1  \n",
       "7609         1  \n",
       "7610         1  \n",
       "7611         1  \n",
       "7612         1  \n",
       "\n",
       "[7613 rows x 5 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Load the datasets\n",
    "train_df = pd.read_csv('train.csv')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a28ce77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>place</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Storm in RI worse than last hurricane. My city...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Green Line derailment in Chicago http://t.co/U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#CityofCalgary has activated its Municipal Eme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword place                                              tweet\n",
       "0         0     NaN   NaN                 Just happened a terrible car crash\n",
       "1         2     NaN   NaN  Heard about #earthquake is different cities, s...\n",
       "2         3     NaN   NaN  there is a forest fire at spot pond, geese are...\n",
       "3         9     NaN   NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4        11     NaN   NaN      Typhoon Soudelor kills 28 in China and Taiwan\n",
       "...     ...     ...   ...                                                ...\n",
       "3258  10861     NaN   NaN  EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...\n",
       "3259  10865     NaN   NaN  Storm in RI worse than last hurricane. My city...\n",
       "3260  10868     NaN   NaN  Green Line derailment in Chicago http://t.co/U...\n",
       "3261  10874     NaN   NaN  MEG issues Hazardous Weather Outlook (HWO) htt...\n",
       "3262  10875     NaN   NaN  #CityofCalgary has activated its Municipal Eme...\n",
       "\n",
       "[3263 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03c47818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing keyword values with 'no_keyword' to ensure no missing values in this important feature\n",
    "\n",
    "train_df['keyword'].fillna('no_keyword', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50c1b10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['keyword'].fillna('no_keyword', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46b6106f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'place' column due to a high number of missing values\n",
    "train_df.drop(columns=['place'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf9ec1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.drop(columns=['place'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8710fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>tweet</th>\n",
       "      <th>disaster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     keyword                                              tweet  disaster\n",
       "0   1  no_keyword  Our Deeds are the Reason of this #earthquake M...         1\n",
       "1   4  no_keyword             Forest fire near La Ronge Sask. Canada         1\n",
       "2   5  no_keyword  All residents asked to 'shelter in place' are ...         1\n",
       "3   6  no_keyword  13,000 people receive #wildfires evacuation or...         1\n",
       "4   7  no_keyword  Just got sent this photo from Ruby #Alaska as ...         1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the datasets to understand their structure\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4136245c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     keyword                                              tweet\n",
       "0   0  no_keyword                 Just happened a terrible car crash\n",
       "1   2  no_keyword  Heard about #earthquake is different cities, s...\n",
       "2   3  no_keyword  there is a forest fire at spot pond, geese are...\n",
       "3   9  no_keyword           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11  no_keyword      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96f9370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb0e45c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Priyanka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Priyanka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Priyanka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK data required for text preprocessing\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7eba8bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess text data\n",
    "def preprocess_text(text):\n",
    "    # Ensure input is string\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert text to lowercase to standardize the text\n",
    "    text = text.lower()\n",
    "    # Remove URLs to avoid noise\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    # Remove HTML tags to clean the text\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    # Remove punctuation to simplify the text\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove numbers to focus on textual content\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Expand common contractions to their full forms\n",
    "    contractions = {\n",
    "        \"can't\": \"cannot\", \"won't\": \"will not\", \"n't\": \" not\", \"'re\": \" are\",\n",
    "        \"'s\": \" is\", \"'d\": \" would\", \"'ll\": \" will\", \"'t\": \" not\",\n",
    "        \"'ve\": \" have\", \"'m\": \" am\"\n",
    "    }\n",
    "    for contraction, full_form in contractions.items():\n",
    "        text = text.replace(contraction, full_form)\n",
    "    # Tokenize the text to break it down into individual words\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stop words that do not contribute much to the meaning\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Lemmatize tokens to reduce words to their base form\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply text preprocessing to the 'tweet' column\n",
    "train_df['clean_tweet'] = train_df['tweet'].apply(preprocess_text)\n",
    "test_df['clean_tweet'] = test_df['tweet'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37de95aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a842e34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with empty 'clean_tweet'\n",
    "train_df = train_df.loc[train_df.clean_tweet != \"\", :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9375eb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "email_train, email_test = train_test_split(train_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa155d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split text into words\n",
    "def split_into_words(i):\n",
    "    return [word for word in i.split(\" \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4ee9d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bag-of-words model\n",
    "emails_bow = CountVectorizer(analyzer=split_into_words).fit(train_df.clean_tweet)\n",
    "all_emails_matrix = emails_bow.transform(train_df.clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64c95160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training messages\n",
    "train_emails_matrix = emails_bow.transform(email_train.clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a19ee7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing messages\n",
    "test_emails_matrix = emails_bow.transform(email_test.clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f2e3973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn term weighting and normalization\n",
    "tfidf_transformer = TfidfTransformer().fit(all_emails_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "945b186a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare TF-IDF for train emails\n",
    "train_tfidf = tfidf_transformer.transform(train_emails_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5502e6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1523, 15768)\n"
     ]
    }
   ],
   "source": [
    "# Prepare TF-IDF for test emails\n",
    "test_tfidf = tfidf_transformer.transform(test_emails_matrix)\n",
    "print(test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41731b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7cf7ddbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    return accuracy, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7aed9c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize an empty dictionary to store the results\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98ea66be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.8003939592908733\n",
      "Naive Bayes Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.90      0.84       874\n",
      "           1       0.83      0.67      0.74       649\n",
      "\n",
      "    accuracy                           0.80      1523\n",
      "   macro avg       0.81      0.78      0.79      1523\n",
      "weighted avg       0.80      0.80      0.80      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "nb_model = MultinomialNB()\n",
    "nb_accuracy, nb_report = evaluate_model(nb_model, train_tfidf, email_train['disaster'], test_tfidf, email_test['disaster'])\n",
    "results['Naive Bayes'] = (nb_accuracy, nb_report)\n",
    "print('Naive Bayes Accuracy:', nb_accuracy)\n",
    "print('Naive Bayes Classification Report:\\n', nb_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f0cd2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7997373604727511\n",
      "Logistic Regression Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.91      0.84       874\n",
      "           1       0.85      0.65      0.73       649\n",
      "\n",
      "    accuracy                           0.80      1523\n",
      "   macro avg       0.81      0.78      0.79      1523\n",
      "weighted avg       0.81      0.80      0.79      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr_model = LogisticRegression()\n",
    "lr_accuracy, lr_report = evaluate_model(lr_model, train_tfidf, email_train['disaster'], test_tfidf, email_test['disaster'])\n",
    "results['Logistic Regression'] = (lr_accuracy, lr_report)\n",
    "print('Logistic Regression Accuracy:', lr_accuracy)\n",
    "print('Logistic Regression Classification Report:\\n', lr_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "612629e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.778069599474721\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.89      0.82       874\n",
      "           1       0.81      0.63      0.71       649\n",
      "\n",
      "    accuracy                           0.78      1523\n",
      "   macro avg       0.79      0.76      0.76      1523\n",
      "weighted avg       0.78      0.78      0.77      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_accuracy, rf_report = evaluate_model(rf_model, train_tfidf, email_train['disaster'], test_tfidf, email_test['disaster'])\n",
    "results['Random Forest'] = (rf_accuracy, rf_report)\n",
    "print('Random Forest Accuracy:', rf_accuracy)\n",
    "print('Random Forest Classification Report:\\n', rf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df6667b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.7957977675640184\n",
      "SVM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83       874\n",
      "           1       0.80      0.69      0.74       649\n",
      "\n",
      "    accuracy                           0.80      1523\n",
      "   macro avg       0.80      0.78      0.79      1523\n",
      "weighted avg       0.80      0.80      0.79      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine (SVM)\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_accuracy, svm_report = evaluate_model(svm_model, train_tfidf, email_train['disaster'], test_tfidf, email_test['disaster'])\n",
    "results['SVM'] = (svm_accuracy, svm_report)\n",
    "print('SVM Accuracy:', svm_accuracy)\n",
    "print('SVM Classification Report:\\n', svm_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b963a8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.7340774786605384\n",
      "Decision Tree Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77       874\n",
      "           1       0.69      0.68      0.69       649\n",
      "\n",
      "    accuracy                           0.73      1523\n",
      "   macro avg       0.73      0.73      0.73      1523\n",
      "weighted avg       0.73      0.73      0.73      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_accuracy, dt_report = evaluate_model(dt_model, train_tfidf, email_train['disaster'], test_tfidf, email_test['disaster'])\n",
    "results['Decision Tree'] = (dt_accuracy, dt_report)\n",
    "print('Decision Tree Accuracy:', dt_accuracy)\n",
    "print('Decision Tree Classification Report:\\n', dt_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2352407d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 0.747209455022981\n",
      "Gradient Boosting Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.93      0.81       874\n",
      "           1       0.84      0.50      0.63       649\n",
      "\n",
      "    accuracy                           0.75      1523\n",
      "   macro avg       0.78      0.72      0.72      1523\n",
      "weighted avg       0.77      0.75      0.73      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "gb_accuracy, gb_report = evaluate_model(gb_model, train_tfidf, email_train['disaster'], test_tfidf, email_test['disaster'])\n",
    "results['Gradient Boosting'] = (gb_accuracy, gb_report)\n",
    "print('Gradient Boosting Accuracy:', gb_accuracy)\n",
    "print('Gradient Boosting Classification Report:\\n', gb_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b47f248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 0.7741300065659882\n",
      "KNN Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.85      0.81       874\n",
      "           1       0.77      0.67      0.72       649\n",
      "\n",
      "    accuracy                           0.77      1523\n",
      "   macro avg       0.77      0.76      0.76      1523\n",
      "weighted avg       0.77      0.77      0.77      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbors (KNN)\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_accuracy, knn_report = evaluate_model(knn_model, train_tfidf, email_train['disaster'], test_tfidf, email_test['disaster'])\n",
    "results['KNN'] = (knn_accuracy, knn_report)\n",
    "print('KNN Accuracy:', knn_accuracy)\n",
    "print('KNN Classification Report:\\n', knn_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5dea8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best model based on accuracy\n",
    "best_model_name = max(results, key=lambda k: results[k][0])\n",
    "best_accuracy, best_report = results[best_model_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce07c1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: Naive Bayes\n"
     ]
    }
   ],
   "source": [
    "print(f'Best Model: {best_model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7dd07020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Accuracy: 0.8003939592908733\n"
     ]
    }
   ],
   "source": [
    "print(f'Best Model Accuracy: {best_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a60a9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.90      0.84       874\n",
      "           1       0.83      0.67      0.74       649\n",
      "\n",
      "    accuracy                           0.80      1523\n",
      "   macro avg       0.81      0.78      0.79      1523\n",
      "weighted avg       0.80      0.80      0.80      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Best Model Classification Report:\\n {best_report}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f0931a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the best model based on best_model_name\n",
    "if best_model_name == \"Naive Bayes\":\n",
    "    best_model = nb_model\n",
    "elif best_model_name == \"Logistic Regression\":\n",
    "    best_model = lr_model\n",
    "elif best_model_name == \"Random Forest\":\n",
    "    best_model = rf_model\n",
    "elif best_model_name == \"SVM\":\n",
    "    best_model = svm_model\n",
    "elif best_model_name == \"Decision Tree\":\n",
    "    best_model = dt_model\n",
    "elif best_model_name == \"Gradient Boosting\":\n",
    "    best_model = gb_model\n",
    "elif best_model_name == \"KNN\":\n",
    "    best_model = knn_model\n",
    "else:\n",
    "    raise ValueError(f\"Model '{best_model_name}' not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c9114d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the test data\n",
    "X_test = emails_bow.transform(test_df['clean_tweet'])\n",
    "test_tfidf = tfidf_transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07b561fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels\n",
    "test_pred = best_model.predict(test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "547e4677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the predictions to the test dataframe\n",
    "test_df['disaster'] = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4457f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[['id', 'disaster']].to_csv(r\"C:\\Users\\Priyanka\\Downloads\\test_predictions.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad0a8e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
